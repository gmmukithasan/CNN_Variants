{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"ALP1X1ckMlfA","execution":{"iopub.status.busy":"2023-08-05T18:03:01.898336Z","iopub.execute_input":"2023-08-05T18:03:01.899199Z","iopub.status.idle":"2023-08-05T18:03:01.914215Z","shell.execute_reply.started":"2023-08-05T18:03:01.899168Z","shell.execute_reply":"2023-08-05T18:03:01.913229Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# VGG16 ON CIFAR_10\n#------------------------------------------------------------------------------\nimport numpy as np\nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport tensorflow.keras as k\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score","metadata":{"id":"NdLh8jiWMqjq","execution":{"iopub.status.busy":"2023-08-05T18:03:01.916220Z","iopub.execute_input":"2023-08-05T18:03:01.916687Z","iopub.status.idle":"2023-08-05T18:03:11.701309Z","shell.execute_reply.started":"2023-08-05T18:03:01.916625Z","shell.execute_reply":"2023-08-05T18:03:11.700266Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# Using VGG16 model, with weights pre-trained on ImageNet.\n#------------------------------------------------------------------------------\n\nvgg16_model = VGG16(weights='imagenet',\n                    include_top=False,\n                    classes=10,\n                    input_shape=(32,32,3)# input: 32x32 images with 3 channels -> (32, 32, 3) tensors.\n                   )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKV7XrrGMtGr","outputId":"cf3eeca4-b1a5-4d99-f133-aa637c1f90fc","execution":{"iopub.status.busy":"2023-08-05T18:03:11.702867Z","iopub.execute_input":"2023-08-05T18:03:11.703648Z","iopub.status.idle":"2023-08-05T18:03:15.354047Z","shell.execute_reply.started":"2023-08-05T18:03:11.703609Z","shell.execute_reply":"2023-08-05T18:03:15.352960Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#Define the sequential model and add th VGG's layers to it\nmodel = Sequential()\nfor layer in vgg16_model.layers:\n    model.add(layer)","metadata":{"id":"kFdfODO2MvAL","execution":{"iopub.status.busy":"2023-08-05T18:03:15.357619Z","iopub.execute_input":"2023-08-05T18:03:15.357911Z","iopub.status.idle":"2023-08-05T18:03:15.459174Z","shell.execute_reply.started":"2023-08-05T18:03:15.357884Z","shell.execute_reply":"2023-08-05T18:03:15.458081Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# Adding hiddens  and output layer to our model\n#------------------------------------------------------------------------------\n\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu', name='hidden1'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(256, activation='relu', name='hidden2'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax', name='predictions'))\n\nmodel.summary()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GTO6p-K_Mwr0","outputId":"bfeb5a34-910d-4a43-b1c6-d6231adb7b4e","execution":{"iopub.status.busy":"2023-08-05T18:03:15.461021Z","iopub.execute_input":"2023-08-05T18:03:15.461923Z","iopub.status.idle":"2023-08-05T18:03:15.583792Z","shell.execute_reply.started":"2023-08-05T18:03:15.461894Z","shell.execute_reply":"2023-08-05T18:03:15.582944Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 512)               0         \n                                                                 \n hidden1 (Dense)             (None, 512)               262656    \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n hidden2 (Dense)             (None, 256)               131328    \n                                                                 \n dropout_1 (Dropout)         (None, 256)               0         \n                                                                 \n predictions (Dense)         (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 15,111,242\nTrainable params: 15,111,242\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n#  Loading CIFAR10 data\n#------------------------------------------------------------------------------\n\n(X_train, y_train), (X_test, y_test) = k.datasets.cifar10.load_data()\n\nprint(\"******************\")\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IZRY2E4MyxB","outputId":"c2ecd97f-3c7a-4500-9a69-3ef3fbcdb631","execution":{"iopub.status.busy":"2023-08-05T18:03:15.584874Z","iopub.execute_input":"2023-08-05T18:03:15.585217Z","iopub.status.idle":"2023-08-05T18:03:21.803245Z","shell.execute_reply.started":"2023-08-05T18:03:15.585182Z","shell.execute_reply":"2023-08-05T18:03:21.802238Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 3s 0us/step\n******************\n(50000, 32, 32, 3)\n(50000, 1)\n(10000, 32, 32, 3)\n(10000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert class vectors to binary class matrices using one hot encoding\ny_train_ohe = to_categorical(y_train, num_classes = 10)\ny_test_ohe = to_categorical(y_test, num_classes = 10)","metadata":{"id":"nbB90jarM0gO","execution":{"iopub.status.busy":"2023-08-05T18:03:21.804748Z","iopub.execute_input":"2023-08-05T18:03:21.805407Z","iopub.status.idle":"2023-08-05T18:03:21.812124Z","shell.execute_reply.started":"2023-08-05T18:03:21.805368Z","shell.execute_reply":"2023-08-05T18:03:21.810990Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Data normalization\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train  /= 255\nX_test /= 255\n\nprint(\"******************\")\nprint(X_train.shape)\nprint(y_train_ohe.shape)\nprint(X_test.shape)\nprint(y_test_ohe.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5o7x5d8nM1_m","outputId":"3ccc96ba-45ce-4abe-e46d-cabf409d7da9","execution":{"iopub.status.busy":"2023-08-05T18:03:21.813713Z","iopub.execute_input":"2023-08-05T18:03:21.814104Z","iopub.status.idle":"2023-08-05T18:03:22.077332Z","shell.execute_reply.started":"2023-08-05T18:03:21.814068Z","shell.execute_reply":"2023-08-05T18:03:22.076162Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"******************\n(50000, 32, 32, 3)\n(50000, 10)\n(10000, 32, 32, 3)\n(10000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_val = X_train[40000:]\ny_val = y_train_ohe[40000:]\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bsPLAzE0M3Yv","outputId":"bdcf28b3-b2f1-43bc-b987-402e47932dcb","execution":{"iopub.status.busy":"2023-08-05T18:03:22.081393Z","iopub.execute_input":"2023-08-05T18:03:22.081724Z","iopub.status.idle":"2023-08-05T18:03:22.088559Z","shell.execute_reply.started":"2023-08-05T18:03:22.081695Z","shell.execute_reply":"2023-08-05T18:03:22.087423Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(10000, 32, 32, 3)\n(10000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train = X_train[:40000]\ny_train_ohe = y_train_ohe[:40000]\nprint(X_train.shape)\nprint(y_train_ohe.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXw9R1YgM4t4","outputId":"1d756043-df7b-4497-fada-0bb16ba374fe","execution":{"iopub.status.busy":"2023-08-05T18:03:22.090087Z","iopub.execute_input":"2023-08-05T18:03:22.090518Z","iopub.status.idle":"2023-08-05T18:03:22.100741Z","shell.execute_reply.started":"2023-08-05T18:03:22.090484Z","shell.execute_reply":"2023-08-05T18:03:22.099365Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(40000, 32, 32, 3)\n(40000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"#------------------------------------------------------------------------------\n# TRAINING THE CNN ON THE TRAIN/VALIDATION DATA\n#------------------------------------------------------------------------------\n\n# initiate SGD optimizer\nsgd = optimizers.SGD(lr=0.001, momentum=0.9)\n\n# For a multi-class classification problem\nmodel.compile(loss='categorical_crossentropy',optimizer= sgd,metrics=['accuracy'])\n\n\ndef lr_scheduler(epoch):\n    return 0.001 * (0.5 ** (epoch // 20))\nreduce_lr = LearningRateScheduler(lr_scheduler)\n\nmc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n\n\n# initialize the number of epochs and batch size\nEPOCHS = 100\nBS = 128\n\n# construct the training image generator for data augmentation\naug = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")\n\n# train the model\nhistory = model.fit(\n    aug.flow(X_train,y_train_ohe, batch_size=BS),\n    validation_data=(X_val,y_val),\n    steps_per_epoch=len(X_train) // BS,\n    epochs=EPOCHS,\n    callbacks=[reduce_lr,mc])\n\n#We load the best weights saved by the ModelCheckpoint\nmodel.load_weights('/kaggle/working/weights.h5')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"TMNaVe-fNA7u","outputId":"27aa993f-02bc-4b28-d4e3-9e01f85c24bd","execution":{"iopub.status.busy":"2023-08-05T19:03:45.198661Z","iopub.execute_input":"2023-08-05T19:03:45.199557Z","iopub.status.idle":"2023-08-05T19:58:45.857893Z","shell.execute_reply.started":"2023-08-05T19:03:45.199511Z","shell.execute_reply":"2023-08-05T19:58:45.856778Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/100\n312/312 [==============================] - 31s 90ms/step - loss: 0.3198 - accuracy: 0.8913 - val_loss: 0.6647 - val_accuracy: 0.8084 - lr: 0.0010\nEpoch 2/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.3065 - accuracy: 0.8973 - val_loss: 0.6691 - val_accuracy: 0.8119 - lr: 0.0010\nEpoch 3/100\n312/312 [==============================] - 29s 92ms/step - loss: 0.3072 - accuracy: 0.8958 - val_loss: 0.6756 - val_accuracy: 0.8147 - lr: 0.0010\nEpoch 4/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.2933 - accuracy: 0.9004 - val_loss: 0.6815 - val_accuracy: 0.8103 - lr: 0.0010\nEpoch 5/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.2901 - accuracy: 0.9026 - val_loss: 0.5748 - val_accuracy: 0.8305 - lr: 0.0010\nEpoch 6/100\n312/312 [==============================] - 29s 92ms/step - loss: 0.2842 - accuracy: 0.9052 - val_loss: 0.5837 - val_accuracy: 0.8317 - lr: 0.0010\nEpoch 7/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.2707 - accuracy: 0.9080 - val_loss: 0.6376 - val_accuracy: 0.8211 - lr: 0.0010\nEpoch 8/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.2635 - accuracy: 0.9113 - val_loss: 0.5945 - val_accuracy: 0.8299 - lr: 0.0010\nEpoch 9/100\n312/312 [==============================] - 28s 91ms/step - loss: 0.2597 - accuracy: 0.9122 - val_loss: 0.6799 - val_accuracy: 0.8157 - lr: 0.0010\nEpoch 10/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.2563 - accuracy: 0.9143 - val_loss: 0.6989 - val_accuracy: 0.8085 - lr: 0.0010\nEpoch 11/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.2619 - accuracy: 0.9121 - val_loss: 0.5982 - val_accuracy: 0.8287 - lr: 0.0010\nEpoch 12/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.2483 - accuracy: 0.9175 - val_loss: 0.6387 - val_accuracy: 0.8255 - lr: 0.0010\nEpoch 13/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.2433 - accuracy: 0.9190 - val_loss: 0.6359 - val_accuracy: 0.8234 - lr: 0.0010\nEpoch 14/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.2377 - accuracy: 0.9202 - val_loss: 0.6842 - val_accuracy: 0.8196 - lr: 0.0010\nEpoch 15/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.2286 - accuracy: 0.9244 - val_loss: 0.7236 - val_accuracy: 0.8085 - lr: 0.0010\nEpoch 16/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.2272 - accuracy: 0.9242 - val_loss: 0.6988 - val_accuracy: 0.8183 - lr: 0.0010\nEpoch 17/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.2173 - accuracy: 0.9276 - val_loss: 0.8827 - val_accuracy: 0.7861 - lr: 0.0010\nEpoch 18/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.2209 - accuracy: 0.9251 - val_loss: 0.6749 - val_accuracy: 0.8232 - lr: 0.0010\nEpoch 19/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.2100 - accuracy: 0.9289 - val_loss: 0.6501 - val_accuracy: 0.8260 - lr: 0.0010\nEpoch 20/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.2031 - accuracy: 0.9301 - val_loss: 0.5963 - val_accuracy: 0.8443 - lr: 0.0010\nEpoch 21/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1636 - accuracy: 0.9452 - val_loss: 0.5812 - val_accuracy: 0.8515 - lr: 5.0000e-04\nEpoch 22/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1501 - accuracy: 0.9502 - val_loss: 0.6167 - val_accuracy: 0.8419 - lr: 5.0000e-04\nEpoch 23/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.1476 - accuracy: 0.9502 - val_loss: 0.6124 - val_accuracy: 0.8431 - lr: 5.0000e-04\nEpoch 24/100\n312/312 [==============================] - 26s 83ms/step - loss: 0.1446 - accuracy: 0.9519 - val_loss: 0.6094 - val_accuracy: 0.8454 - lr: 5.0000e-04\nEpoch 25/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.1406 - accuracy: 0.9522 - val_loss: 0.6831 - val_accuracy: 0.8323 - lr: 5.0000e-04\nEpoch 26/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.1357 - accuracy: 0.9559 - val_loss: 0.6977 - val_accuracy: 0.8322 - lr: 5.0000e-04\nEpoch 27/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.1390 - accuracy: 0.9545 - val_loss: 0.6628 - val_accuracy: 0.8373 - lr: 5.0000e-04\nEpoch 28/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1316 - accuracy: 0.9557 - val_loss: 0.6729 - val_accuracy: 0.8336 - lr: 5.0000e-04\nEpoch 29/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1313 - accuracy: 0.9574 - val_loss: 0.7151 - val_accuracy: 0.8273 - lr: 5.0000e-04\nEpoch 30/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.1250 - accuracy: 0.9589 - val_loss: 0.6994 - val_accuracy: 0.8332 - lr: 5.0000e-04\nEpoch 31/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.1304 - accuracy: 0.9561 - val_loss: 0.6966 - val_accuracy: 0.8325 - lr: 5.0000e-04\nEpoch 32/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.1307 - accuracy: 0.9575 - val_loss: 0.7169 - val_accuracy: 0.8319 - lr: 5.0000e-04\nEpoch 33/100\n312/312 [==============================] - 26s 84ms/step - loss: 0.1222 - accuracy: 0.9601 - val_loss: 0.6577 - val_accuracy: 0.8406 - lr: 5.0000e-04\nEpoch 34/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1207 - accuracy: 0.9599 - val_loss: 0.7032 - val_accuracy: 0.8362 - lr: 5.0000e-04\nEpoch 35/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1252 - accuracy: 0.9582 - val_loss: 0.7090 - val_accuracy: 0.8327 - lr: 5.0000e-04\nEpoch 36/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.1213 - accuracy: 0.9598 - val_loss: 0.7257 - val_accuracy: 0.8314 - lr: 5.0000e-04\nEpoch 37/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1205 - accuracy: 0.9603 - val_loss: 0.7049 - val_accuracy: 0.8312 - lr: 5.0000e-04\nEpoch 38/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.1161 - accuracy: 0.9616 - val_loss: 0.6799 - val_accuracy: 0.8328 - lr: 5.0000e-04\nEpoch 39/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.1133 - accuracy: 0.9631 - val_loss: 0.7298 - val_accuracy: 0.8249 - lr: 5.0000e-04\nEpoch 40/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.1113 - accuracy: 0.9619 - val_loss: 0.6765 - val_accuracy: 0.8345 - lr: 5.0000e-04\nEpoch 41/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0918 - accuracy: 0.9704 - val_loss: 0.7423 - val_accuracy: 0.8333 - lr: 2.5000e-04\nEpoch 42/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.0911 - accuracy: 0.9703 - val_loss: 0.7493 - val_accuracy: 0.8297 - lr: 2.5000e-04\nEpoch 43/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.0887 - accuracy: 0.9711 - val_loss: 0.7416 - val_accuracy: 0.8355 - lr: 2.5000e-04\nEpoch 44/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0842 - accuracy: 0.9719 - val_loss: 0.7569 - val_accuracy: 0.8342 - lr: 2.5000e-04\nEpoch 45/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.0827 - accuracy: 0.9733 - val_loss: 0.7426 - val_accuracy: 0.8357 - lr: 2.5000e-04\nEpoch 46/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.0794 - accuracy: 0.9741 - val_loss: 0.7398 - val_accuracy: 0.8401 - lr: 2.5000e-04\nEpoch 47/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0825 - accuracy: 0.9728 - val_loss: 0.7266 - val_accuracy: 0.8390 - lr: 2.5000e-04\nEpoch 48/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.0776 - accuracy: 0.9746 - val_loss: 0.7211 - val_accuracy: 0.8411 - lr: 2.5000e-04\nEpoch 49/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.0791 - accuracy: 0.9740 - val_loss: 0.7405 - val_accuracy: 0.8411 - lr: 2.5000e-04\nEpoch 50/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0825 - accuracy: 0.9724 - val_loss: 0.7249 - val_accuracy: 0.8401 - lr: 2.5000e-04\nEpoch 51/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.0809 - accuracy: 0.9730 - val_loss: 0.7028 - val_accuracy: 0.8422 - lr: 2.5000e-04\nEpoch 52/100\n312/312 [==============================] - 27s 88ms/step - loss: 0.0814 - accuracy: 0.9736 - val_loss: 0.7357 - val_accuracy: 0.8401 - lr: 2.5000e-04\nEpoch 53/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0805 - accuracy: 0.9736 - val_loss: 0.7210 - val_accuracy: 0.8422 - lr: 2.5000e-04\nEpoch 54/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 0.6963 - val_accuracy: 0.8501 - lr: 2.5000e-04\nEpoch 55/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.0772 - accuracy: 0.9745 - val_loss: 0.7117 - val_accuracy: 0.8430 - lr: 2.5000e-04\nEpoch 56/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.0714 - accuracy: 0.9765 - val_loss: 0.7248 - val_accuracy: 0.8417 - lr: 2.5000e-04\nEpoch 57/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0761 - accuracy: 0.9754 - val_loss: 0.7490 - val_accuracy: 0.8391 - lr: 2.5000e-04\nEpoch 58/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0773 - accuracy: 0.9749 - val_loss: 0.6826 - val_accuracy: 0.8473 - lr: 2.5000e-04\nEpoch 59/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0740 - accuracy: 0.9753 - val_loss: 0.7312 - val_accuracy: 0.8418 - lr: 2.5000e-04\nEpoch 60/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.0751 - accuracy: 0.9749 - val_loss: 0.8051 - val_accuracy: 0.8303 - lr: 2.5000e-04\nEpoch 61/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.0681 - accuracy: 0.9785 - val_loss: 0.7304 - val_accuracy: 0.8442 - lr: 1.2500e-04\nEpoch 62/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.7348 - val_accuracy: 0.8433 - lr: 1.2500e-04\nEpoch 63/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.7095 - val_accuracy: 0.8480 - lr: 1.2500e-04\nEpoch 64/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.7409 - val_accuracy: 0.8434 - lr: 1.2500e-04\nEpoch 65/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0577 - accuracy: 0.9814 - val_loss: 0.7480 - val_accuracy: 0.8433 - lr: 1.2500e-04\nEpoch 66/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0595 - accuracy: 0.9800 - val_loss: 0.7382 - val_accuracy: 0.8462 - lr: 1.2500e-04\nEpoch 67/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0633 - accuracy: 0.9793 - val_loss: 0.7466 - val_accuracy: 0.8454 - lr: 1.2500e-04\nEpoch 68/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0614 - accuracy: 0.9802 - val_loss: 0.7454 - val_accuracy: 0.8430 - lr: 1.2500e-04\nEpoch 69/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0631 - accuracy: 0.9791 - val_loss: 0.7585 - val_accuracy: 0.8438 - lr: 1.2500e-04\nEpoch 70/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.0615 - accuracy: 0.9799 - val_loss: 0.7296 - val_accuracy: 0.8467 - lr: 1.2500e-04\nEpoch 71/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0572 - accuracy: 0.9819 - val_loss: 0.7570 - val_accuracy: 0.8441 - lr: 1.2500e-04\nEpoch 72/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0578 - accuracy: 0.9817 - val_loss: 0.7447 - val_accuracy: 0.8462 - lr: 1.2500e-04\nEpoch 73/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 0.7682 - val_accuracy: 0.8446 - lr: 1.2500e-04\nEpoch 74/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0581 - accuracy: 0.9812 - val_loss: 0.7471 - val_accuracy: 0.8457 - lr: 1.2500e-04\nEpoch 75/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.0600 - accuracy: 0.9806 - val_loss: 0.7434 - val_accuracy: 0.8422 - lr: 1.2500e-04\nEpoch 76/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0559 - accuracy: 0.9822 - val_loss: 0.7440 - val_accuracy: 0.8453 - lr: 1.2500e-04\nEpoch 77/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.7691 - val_accuracy: 0.8437 - lr: 1.2500e-04\nEpoch 78/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.7575 - val_accuracy: 0.8486 - lr: 1.2500e-04\nEpoch 79/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0555 - accuracy: 0.9816 - val_loss: 0.7892 - val_accuracy: 0.8407 - lr: 1.2500e-04\nEpoch 80/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 0.7747 - val_accuracy: 0.8440 - lr: 1.2500e-04\nEpoch 81/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.7434 - val_accuracy: 0.8470 - lr: 6.2500e-05\nEpoch 82/100\n312/312 [==============================] - 28s 89ms/step - loss: 0.0524 - accuracy: 0.9830 - val_loss: 0.7621 - val_accuracy: 0.8459 - lr: 6.2500e-05\nEpoch 83/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0519 - accuracy: 0.9829 - val_loss: 0.7706 - val_accuracy: 0.8467 - lr: 6.2500e-05\nEpoch 84/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.7508 - val_accuracy: 0.8478 - lr: 6.2500e-05\nEpoch 85/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0517 - accuracy: 0.9829 - val_loss: 0.7586 - val_accuracy: 0.8468 - lr: 6.2500e-05\nEpoch 86/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.7489 - val_accuracy: 0.8469 - lr: 6.2500e-05\nEpoch 87/100\n312/312 [==============================] - 26s 85ms/step - loss: 0.0479 - accuracy: 0.9840 - val_loss: 0.7630 - val_accuracy: 0.8462 - lr: 6.2500e-05\nEpoch 88/100\n312/312 [==============================] - 27s 85ms/step - loss: 0.0480 - accuracy: 0.9846 - val_loss: 0.7542 - val_accuracy: 0.8477 - lr: 6.2500e-05\nEpoch 89/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0475 - accuracy: 0.9849 - val_loss: 0.7559 - val_accuracy: 0.8480 - lr: 6.2500e-05\nEpoch 90/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0504 - accuracy: 0.9838 - val_loss: 0.7772 - val_accuracy: 0.8423 - lr: 6.2500e-05\nEpoch 91/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.7672 - val_accuracy: 0.8453 - lr: 6.2500e-05\nEpoch 92/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0510 - accuracy: 0.9831 - val_loss: 0.7682 - val_accuracy: 0.8452 - lr: 6.2500e-05\nEpoch 93/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 0.7602 - val_accuracy: 0.8482 - lr: 6.2500e-05\nEpoch 94/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.7838 - val_accuracy: 0.8459 - lr: 6.2500e-05\nEpoch 95/100\n312/312 [==============================] - 27s 86ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 0.7695 - val_accuracy: 0.8460 - lr: 6.2500e-05\nEpoch 96/100\n312/312 [==============================] - 28s 90ms/step - loss: 0.0456 - accuracy: 0.9850 - val_loss: 0.7855 - val_accuracy: 0.8453 - lr: 6.2500e-05\nEpoch 97/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0509 - accuracy: 0.9831 - val_loss: 0.7607 - val_accuracy: 0.8450 - lr: 6.2500e-05\nEpoch 98/100\n312/312 [==============================] - 27s 87ms/step - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.7915 - val_accuracy: 0.8424 - lr: 6.2500e-05\nEpoch 99/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.7741 - val_accuracy: 0.8460 - lr: 6.2500e-05\nEpoch 100/100\n312/312 [==============================] - 28s 88ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 0.7802 - val_accuracy: 0.8433 - lr: 6.2500e-05\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss, train_accuracy = model.evaluate_generator(aug.flow(X_train,y_train_ohe, batch_size=BS), 156)\nprint('Training loss: {}\\nTraining accuracy: {}'.format(train_loss, train_accuracy))","metadata":{"id":"U3Sl8NMTNG4m","execution":{"iopub.status.busy":"2023-08-05T19:59:53.398133Z","iopub.execute_input":"2023-08-05T19:59:53.399242Z","iopub.status.idle":"2023-08-05T20:00:04.989209Z","shell.execute_reply.started":"2023-08-05T19:59:53.399196Z","shell.execute_reply":"2023-08-05T20:00:04.988046Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_28/2348676300.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n  train_loss, train_accuracy = model.evaluate_generator(aug.flow(X_train,y_train_ohe, batch_size=BS), 156)\n","output_type":"stream"},{"name":"stdout","text":"Training loss: 0.13861186802387238\nTraining accuracy: 0.9529246687889099\n","output_type":"stream"}]},{"cell_type":"code","source":"val_loss, val_accuracy = model.evaluate(X_val, y_val)\nprint('Validation loss: {}\\nValidation accuracy: {}'.format(val_loss, val_accuracy))","metadata":{"id":"_TDhon5ZNIJ3","execution":{"iopub.status.busy":"2023-08-05T20:00:09.344914Z","iopub.execute_input":"2023-08-05T20:00:09.345603Z","iopub.status.idle":"2023-08-05T20:00:11.782944Z","shell.execute_reply.started":"2023-08-05T20:00:09.345565Z","shell.execute_reply":"2023-08-05T20:00:11.782034Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 2s 6ms/step - loss: 0.5812 - accuracy: 0.8515\nValidation loss: 0.5811823010444641\nValidation accuracy: 0.8514999747276306\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(X_test,y_test_ohe,)\nprint('Testing loss: {}\\nTesting accuracy: {}'.format(test_loss, test_accuracy))","metadata":{"id":"XKuujF82NNVR","execution":{"iopub.status.busy":"2023-08-05T20:00:15.912201Z","iopub.execute_input":"2023-08-05T20:00:15.912628Z","iopub.status.idle":"2023-08-05T20:00:18.372973Z","shell.execute_reply.started":"2023-08-05T20:00:15.912594Z","shell.execute_reply":"2023-08-05T20:00:18.371931Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 2s 7ms/step - loss: 0.6155 - accuracy: 0.8427\nTesting loss: 0.6155045628547668\nTesting accuracy: 0.8427000045776367\n","output_type":"stream"}]}]}